**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report #3 – Code Coverage, Adequacy Criteria and Test Case Correlation**

| Group 23:         |          |
| ----------------- | -------- |
| Nicole Heather    | 30163278 |
| Nora Melik        |          |
| Nelson Thompson   |          |
| Jennifer Jay      |          |

(Note that some labs require individual reports while others require one report
for each group. Please see each lab document for details.)

# Outline

This design component requires that you and your team measure the adequacy of your test suite using one or more code coverage tools and report about the pros and cons of your metrics and tool choices

Measurement of code coverage is performed in two main steps. First, classes must be selected for instrumentation. Classes selected for instrumentation are the classes which will have the coverage measured. Then, the test suite must be run with a coverage tool. You can use any coverage analysis tool. You need to report three coverage metrics (the suggested metrics to report are: statement, branch, and condition coverages).

NOTE1: If the coverage tool that you are using does not support any of the above metrics, first try another tool. If none reports the above measures, then replace the missing measure with another metric that the tool supports, e.g. you might decide to replace condition coverage with method coverage, if you are using EclEmma

NOTE2: Document all coverage tools you tried and what worked or did not work for your configuration. Explain what you fixed (e.g., removing mock objects, updating IDEs, switching to another tool, etc.)

NOTE3: You need to report the pros and cons of tools you tried and the metrics you chose.

To become more familiar with data flow coverage and achieve a deeper understanding of how coverage tools work, calculate the DU-pair coverage for two methods, by hand. The methods to analyze are: DataUtilities.calculateColumnTotal and one method of your choice from the org.jfree.data.Range class (that you have a test set for, from Assignment 2). Calculate the DU-pair coverage by tracing through the execution of each of your test cases for these methods, manually. This will need to be included in your report. You need to report the followings per method:

the data flow graph

the def-use sets per statement

list all DU-pairs per variable

for each test case show which pairs are covered

calculate the DU-Pair coverage

In this section, you will be required to design new unit tests for two classes to increase their code coverage. The classes to be tested are: org.jfree.data.DataUtilities and org.jfree.data.Range. Note that although the focus in adequacy criteria has changed (it is now on source code), to develop new test cases the test oracle should still be derived from the requirements (as contained in the Javadocs of the SUT)

As with any testing to be done, to begin with, a plan must be created. Document this test plan, as it will be included with your lab report. This plan should include information about who will create which tests, how you plan to develop tests to achieve the adequacy criteria. For thiassignment, a test suite should be developed which has at least thfollowing coverage for each of the classes under test

Minimum coverage:

90% statement coverage

70% branch coverage

60% condition coverage

Students should now have a good understanding of measuring test suite adequacy based on coverage of the SUT’s code. This should include an understanding of some of the different control flow and data flow coverage criteria, and the relative difficulty to satisfy these coverage criteria. Students should now have an idea of some of the trade-offs that occur when choosing different test suite adequacy criteria for testing

# 1 Introduction



# 2 Manual data-flow coverage calculations for X and Y methods

Check coverage for current tests

# 3 A detailed description of the testing strategy for the new unit test


1. Statement Coverage
     Rationale (why do we need it): Faults cannot be discovered
    if code lines containing them are not executed
     Statement coverage criterion: Equivalent to covering all
    nodes in CFG
     Executing a statement is a weak guarantee of correctness,
    but rather easy to achieve
     In general, several inputs execute the same statements

2. Decision (Branch) Coverage
     Branch coverage relates to decisions in
    a program
     e.g. an IF statement has always two
    branches
     Example: Branch coverage for the
    example given TC: (a = 1, b = 2)
     Given control flow graph (CFG)
    of a program
     Select a test set such that, by
    executing the program for each
    test case in the set, each edge of
    CFG’s decision (predicate)
    node(s) is traversed at least once
     We need to exercise all decision
    that traverse the control flow of
    the program with True and False
    values

    3. Condition Coverage
     Condition coverage is a more powerful test coverage criteria
     Condition Coverage (CC) Criterion: Design a test set such that each
    individual condition in the program to be both True and False
    (regardless of the truth or falsity of predicates combining those
    conditions)  this may cause branch coverage suffer though (see next
    slide’s example)
     We should usually consider both branch (decision) and condition
    coverage together
     How? by executing the program for each element in the set, all
    possible values of the constituents of compound conditions (defined
    below) are exercised at least once
     Compound conditions: C1 and C2 or C3 ... where Ci’s are relational
    expressions or Boolean variables (atomic conditions)
    49



# 4 A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage

Talk about changes made to past code 

# 5 A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice)

Just run the coverage thing, after we create new ones

# 6 Pros and Cons of coverage tools used and Metrics you report

Text…

# 7 A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation.

Text…

# 8 A discussion on how the team work/effort was divided and managed

Text…

# 9 Any difficulties encountered, challenges overcome, and lessons learned from performing the lab

Text…

# 10 Comments/feedback on the lab itself

Text…
